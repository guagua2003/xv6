diff --git a/kernel/bio.c b/kernel/bio.c
index 60d91a6..41b987b 100644
--- a/kernel/bio.c
+++ b/kernel/bio.c
@@ -23,33 +23,43 @@
 #include "fs.h"
 #include "buf.h"
 
+#define NBUCKET 13
+
 struct {
-  struct spinlock lock;
+  struct spinlock lock[NBUCKET];
   struct buf buf[NBUF];
-
-  // Linked list of all buffers, through prev/next.
-  // Sorted by how recently the buffer was used.
-  // head.next is most recent, head.prev is least.
-  struct buf head;
+  struct buf head[NBUCKET];
 } bcache;
 
+int hash (int n) {
+  return n % NBUCKET;
+}
+
 void
 binit(void)
 {
   struct buf *b;
+  
+  for (int i = 0; i < NBUCKET; i++) {
+    initlock(&(bcache.lock[i]), "bcache.hash");
+  }
 
-  initlock(&bcache.lock, "bcache");
-
-  // Create linked list of buffers
-  bcache.head.prev = &bcache.head;
-  bcache.head.next = &bcache.head;
-  for(b = bcache.buf; b < bcache.buf+NBUF; b++){
-    b->next = bcache.head.next;
-    b->prev = &bcache.head;
+  bcache.head[0].next = &bcache.buf[0];
+  for (b = bcache.buf; b < bcache.buf+NBUF-1; b++) {
+    b->next = b+1;
     initsleeplock(&b->lock, "buffer");
-    bcache.head.next->prev = b;
-    bcache.head.next = b;
   }
+  initsleeplock(&b->lock, "buffer");
+}
+
+void 
+write_cache(struct buf *take_buf, uint dev, uint blockno)
+{
+  take_buf->dev = dev;
+  take_buf->blockno = blockno;
+  take_buf->valid = 0;
+  take_buf->refcnt = 1;
+  take_buf->time = ticks;
 }
 
 // Look through buffer cache for block on device dev.
@@ -58,36 +68,90 @@ binit(void)
 static struct buf*
 bget(uint dev, uint blockno)
 {
-  struct buf *b;
-
-  acquire(&bcache.lock);
+  struct buf *b, *last;
+  struct buf *take_buf = 0;
+  int id = hash(blockno);
+  acquire(&(bcache.lock[id]));
 
   // Is the block already cached?
-  for(b = bcache.head.next; b != &bcache.head; b = b->next){
-    if(b->dev == dev && b->blockno == blockno){
+  for(b = bcache.head[id].next, last = &(bcache.head[id]); b; b = b->next, last = last->next)
+  {
+
+    if(b->dev == dev && b->blockno == blockno)
+    {
+      b->time = ticks;
       b->refcnt++;
-      release(&bcache.lock);
+      release(&(bcache.lock[id]));
       acquiresleep(&b->lock);
       return b;
     }
+    if(b->refcnt == 0)
+    {
+      take_buf = b;
+    }
   }
 
-  // Not cached.
-  // Recycle the least recently used (LRU) unused buffer.
-  for(b = bcache.head.prev; b != &bcache.head; b = b->prev){
-    if(b->refcnt == 0) {
-      b->dev = dev;
-      b->blockno = blockno;
-      b->valid = 0;
-      b->refcnt = 1;
-      release(&bcache.lock);
-      acquiresleep(&b->lock);
-      return b;
+  if(take_buf)
+  { 
+    write_cache(take_buf, dev, blockno);
+    release(&(bcache.lock[id]));
+    acquiresleep(&(take_buf->lock));
+    return take_buf;
+  }
+
+  int lock_num = -1;
+  
+  uint time = __UINT32_MAX__;
+  struct buf *tmp;
+  struct buf *last_take = 0;
+  for(int i = 0; i < NBUCKET; ++i)
+  {
+    
+    if(i == id) continue;
+	
+    acquire(&(bcache.lock[i]));
+
+    for(b = bcache.head[i].next, tmp = &(bcache.head[i]); b; b = b->next,tmp = tmp->next)
+    {
+      if(b->refcnt == 0)
+      {
+        if(b->time < time)
+        {
+          
+          time = b->time;
+          last_take = tmp;
+          take_buf = b;
+          
+          if(lock_num != -1 && lock_num != i && holding(&(bcache.lock[lock_num])))
+            release(&(bcache.lock[lock_num]));
+          lock_num = i;
+        }
+      }
     }
+	
+    if(lock_num != i)
+      release(&(bcache.lock[i]));
   }
-  panic("bget: no buffers");
+  
+  if (!take_buf) 
+    panic("bget: no buffers");
+  
+  last_take->next = take_buf->next;
+  take_buf->next = 0;
+  release(&(bcache.lock[lock_num]));
+  
+  b = last;
+  b->next = take_buf;
+  write_cache(take_buf, dev, blockno);
+
+
+  release(&(bcache.lock[id]));
+  acquiresleep(&(take_buf->lock));
+  
+  return take_buf;
 }
 
+
 // Return a locked buf with the contents of the indicated block.
 struct buf*
 bread(uint dev, uint blockno)
@@ -121,33 +185,24 @@ brelse(struct buf *b)
 
   releasesleep(&b->lock);
 
-  acquire(&bcache.lock);
-  b->refcnt--;
-  if (b->refcnt == 0) {
-    // no one is waiting for it.
-    b->next->prev = b->prev;
-    b->prev->next = b->next;
-    b->next = bcache.head.next;
-    b->prev = &bcache.head;
-    bcache.head.next->prev = b;
-    bcache.head.next = b;
-  }
-  
-  release(&bcache.lock);
+  int id = hash(b->blockno);
+  acquire(&bcache.lock[id]);
+  b->refcnt--;  
+  release(&bcache.lock[id]);
 }
 
 void
 bpin(struct buf *b) {
-  acquire(&bcache.lock);
+  int id = hash(b->blockno);
+  acquire(&(bcache.lock[id]));
   b->refcnt++;
-  release(&bcache.lock);
+  release(&(bcache.lock[id]));
 }
 
 void
 bunpin(struct buf *b) {
-  acquire(&bcache.lock);
+  int id = hash(b->blockno);
+  acquire(&(bcache.lock[id]));
   b->refcnt--;
-  release(&bcache.lock);
+  release(&(bcache.lock[id]));
 }
-
-
diff --git a/kernel/buf.h b/kernel/buf.h
index 4616e9e..22add26 100644
--- a/kernel/buf.h
+++ b/kernel/buf.h
@@ -8,5 +8,6 @@ struct buf {
   struct buf *prev; // LRU cache list
   struct buf *next;
   uchar data[BSIZE];
+  uint time;
 };
 
diff --git a/kernel/kalloc.c b/kernel/kalloc.c
index fa6a0ac..6906d7e 100644
--- a/kernel/kalloc.c
+++ b/kernel/kalloc.c
@@ -18,15 +18,20 @@ struct run {
   struct run *next;
 };
 
-struct {
+struct kmem{
   struct spinlock lock;
   struct run *freelist;
-} kmem;
+};
+
+struct kmem kmem_sum[NCPU];
 
 void
 kinit()
 {
-  initlock(&kmem.lock, "kmem");
+  int i;
+  for(i = 0; i < NCPU; ++i)
+    initlock(&(kmem_sum[i].lock), "kmem");
+    
   freerange(end, (void*)PHYSTOP);
 }
 
@@ -56,10 +61,13 @@ kfree(void *pa)
 
   r = (struct run*)pa;
 
-  acquire(&kmem.lock);
-  r->next = kmem.freelist;
-  kmem.freelist = r;
-  release(&kmem.lock);
+  push_off();
+  int id = cpuid();
+  acquire(&(kmem_sum[id].lock));
+  r->next = kmem_sum[id].freelist;
+  kmem_sum[id].freelist = r;
+  release(&(kmem_sum[id].lock));
+  pop_off();
 }
 
 // Allocate one 4096-byte page of physical memory.
@@ -70,11 +78,35 @@ kalloc(void)
 {
   struct run *r;
 
-  acquire(&kmem.lock);
-  r = kmem.freelist;
+  push_off();
+
+  int id = cpuid();
+  acquire(&(kmem_sum[id].lock));
+  r = kmem_sum[id].freelist;
+  
   if(r)
-    kmem.freelist = r->next;
-  release(&kmem.lock);
+    kmem_sum[id].freelist = r->next;
+  else
+  {
+    for(int i = 0; i < NCPU; ++i)
+    {
+      if(i == id) 
+	  	continue;
+
+      acquire(&(kmem_sum[i].lock));
+      r = kmem_sum[i].freelist;
+      if(r)
+      {
+        kmem_sum[i].freelist = r->next;
+        release(&(kmem_sum[i].lock));
+        break;
+      }
+
+      release(&(kmem_sum[i].lock));
+    }
+  }
+  release(&(kmem_sum[id].lock));
+  pop_off();
 
   if(r)
     memset((char*)r, 5, PGSIZE); // fill with junk
diff --git a/kernel/param.h b/kernel/param.h
index b5fdcb2..ebc2d3d 100644
--- a/kernel/param.h
+++ b/kernel/param.h
@@ -8,6 +8,6 @@
 #define MAXARG       32  // max exec arguments
 #define MAXOPBLOCKS  10  // max # of blocks any FS op writes
 #define LOGSIZE      (MAXOPBLOCKS*3)  // max data blocks in on-disk log
-#define NBUF         (MAXOPBLOCKS*3)  // size of disk block cache
-#define FSSIZE       1000  // size of file system in blocks
+#define NBUF         (MAXOPBLOCKS*4)  // size of disk block cache
+#define FSSIZE       10000  // size of file system in blocks
 #define MAXPATH      128   // maximum file path name
diff --git a/time.txt b/time.txt
new file mode 100644
index 0000000..86ee83a
--- /dev/null
+++ b/time.txt
@@ -0,0 +1 @@
+40
\ No newline at end of file
